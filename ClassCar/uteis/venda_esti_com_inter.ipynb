{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1002f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q pandas scikit-learn joblib ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38cbe03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, sqlite3, warnings, math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as W\n",
    "\n",
    "# Configura√ß√µes principais\n",
    "ANO_ATUAL   = 2025\n",
    "QUANTIS     = [0.10, 0.50, 0.90]   # ‚âà m√≠nimo, mediana, m√°ximo\n",
    "DB_PATH     = \"sorteio_carros100k.db\"   # <-- seu banco\n",
    "TABLE       = \"sorteio\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb2bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def km_ano_e_perfil(ano: int, km_total: int, ano_atual: int = ANO_ATUAL):\n",
    "    \"\"\"\n",
    "    Calcula km/ano e classifica o Perfil de Rodagem automaticamente:\n",
    "      ‚â§ 7.000  -> Pouco Rodado\n",
    "      ‚â§ 12.000 -> Normal\n",
    "      ‚â§ 20.000 -> Alto\n",
    "      > 20.000 -> Super Alto\n",
    "    \"\"\"\n",
    "    idade = max(0, int(ano_atual) - int(ano))\n",
    "    km_ano = float(km_total) / (idade if idade > 0 else 0.5)\n",
    "    if km_ano <= 7000:\n",
    "        perfil = \"Pouco Rodado\"\n",
    "    elif km_ano <= 12000:\n",
    "        perfil = \"Normal\"\n",
    "    elif km_ano <= 20000:\n",
    "        perfil = \"Alto\"\n",
    "    else:\n",
    "        perfil = \"Super Alto\"\n",
    "    return km_ano, perfil\n",
    "\n",
    "def map_estado_para_nota(estado: str) -> float:\n",
    "    \"\"\"Mapeia r√≥tulo de estado para nota ~[3.0, 5.0].\"\"\"\n",
    "    if not estado: return 4.0\n",
    "    e = estado.strip().lower()\n",
    "    mapa = {\n",
    "        \"ruim\": 3.0, \"fraco\": 3.0, \"fraca\": 3.0,\n",
    "        \"medio\": 3.5, \"m√©dio\": 3.5, \"regular\": 3.5,\n",
    "        \"bom\": 4.0, \"boa\": 4.0,\n",
    "        \"otimo\": 4.5, \"√≥timo\": 4.5, \"muito bom\": 4.5,\n",
    "        \"excelente\": 4.9\n",
    "    }\n",
    "    return float(mapa.get(e, 4.0))\n",
    "\n",
    "def build_preprocessor(categorical_cols, numeric_cols):\n",
    "    # Compat√≠vel com vers√µes novas/antigas do scikit-learn\n",
    "    try:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    except TypeError:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", ohe, categorical_cols),\n",
    "            (\"num\", \"passthrough\", numeric_cols)\n",
    "        ]\n",
    "    )\n",
    "    return pre\n",
    "\n",
    "def fit_quantile_models(X, y, sample_weight, quantis=QUANTIS, random_state=42):\n",
    "    models = {}\n",
    "    for q in quantis:\n",
    "        model = GradientBoostingRegressor(\n",
    "            loss=\"quantile\", alpha=q,\n",
    "            n_estimators=300, learning_rate=0.05, max_depth=3,\n",
    "            subsample=0.9, random_state=random_state\n",
    "        )\n",
    "        model.fit(X, y, sample_weight=sample_weight)\n",
    "        models[q] = model\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d9cdb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar do SQLite\n",
    "if not os.path.exists(DB_PATH):\n",
    "    raise FileNotFoundError(f\"N√£o encontrei o banco: {os.path.abspath(DB_PATH)}\")\n",
    "\n",
    "con = sqlite3.connect(DB_PATH)\n",
    "DF_BASE = pd.read_sql_query(f\"SELECT * FROM {TABLE}\", con)\n",
    "con.close()\n",
    "\n",
    "if \"Dias_para_Venda\" not in DF_BASE.columns:\n",
    "    raise ValueError(f\"A tabela {TABLE} precisa ter a coluna 'Dias_para_Venda'.\")\n",
    "\n",
    "# Colunas autom√°ticas\n",
    "DF_BASE = DF_BASE.copy()\n",
    "tmp = DF_BASE.apply(lambda r: km_ano_e_perfil(r[\"Ano\"], r[\"Quilometragem_Estimada\"]), axis=1)\n",
    "DF_BASE[\"KM_Ano_auto\"] = tmp.apply(lambda x: x[0])\n",
    "DF_BASE[\"Perfil_Rodagem_auto\"] = tmp.apply(lambda x: x[1])\n",
    "\n",
    "# Listas para interface\n",
    "LIST_MARCAS  = sorted(DF_BASE[\"Marca\"].dropna().unique().tolist())\n",
    "LIST_CORES   = sorted(DF_BASE[\"Cor\"].dropna().unique().tolist())\n",
    "LIST_ESTADOS = [\"ruim\",\"medio\",\"bom\",\"otimo\",\"excelente\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b5448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimativa_empirica(df_base: pd.DataFrame, marca, modelo, ano, km,\n",
    "                        janela_anos=2, janela_km_perc=0.20, min_amostra=30):\n",
    "    df = df_base[(df_base[\"Marca\"] == marca) & (df_base[\"Modelo\"] == modelo)].copy()\n",
    "    if df.empty:\n",
    "        return None\n",
    "\n",
    "    ano_min, ano_max = ano - janela_anos, ano + janela_anos\n",
    "    km_min, km_max   = km * (1 - janela_km_perc), km * (1 + janela_km_perc)\n",
    "    sub = df[(df[\"Ano\"].between(ano_min, ano_max)) &\n",
    "             (df[\"Quilometragem_Estimada\"].between(km_min, km_max))].copy()\n",
    "\n",
    "    widen = 0\n",
    "    while len(sub) < min_amostra and widen < 3:\n",
    "        widen += 1\n",
    "        j2 = janela_anos + widen\n",
    "        p2 = janela_km_perc + 0.10*widen\n",
    "        ano_min, ano_max = ano - j2, ano + j2\n",
    "        km_min, km_max   = km * (1 - p2), km * (1 + p2)\n",
    "        sub = df[(df[\"Ano\"].between(ano_min, ano_max)) &\n",
    "                 (df[\"Quilometragem_Estimada\"].between(km_min, km_max))].copy()\n",
    "\n",
    "    if sub.empty:\n",
    "        return None\n",
    "\n",
    "    dias = sub[\"Dias_para_Venda\"].astype(float)\n",
    "    q10, q50, q90 = dias.quantile([0.10, 0.50, 0.90])\n",
    "    media, desvio = dias.mean(), dias.std(ddof=1)\n",
    "\n",
    "    return {\n",
    "        \"M√©todo\": \"Emp√≠rico (filtros)\",\n",
    "        \"N\": int(len(sub)),\n",
    "        \"M√≠n\": round(q10,1), \"Med\": round(q50,1), \"M√°x\": round(q90,1),\n",
    "        \"M√©dia ¬± DP\": f\"{media:.1f} ¬± {desvio:.1f}\"\n",
    "    }\n",
    "\n",
    "def estimativa_knn_auto(df_base: pd.DataFrame, marca, modelo, ano, km, cor=None, k=50):\n",
    "    df = df_base[(df_base[\"Marca\"] == marca) & (df_base[\"Modelo\"] == modelo)].copy()\n",
    "    if df.empty:\n",
    "        return None\n",
    "\n",
    "    # Refor√ßo de sem√¢ntica: garantir colunas auto\n",
    "    if \"KM_Ano_auto\" not in df.columns or \"Perfil_Rodagem_auto\" not in df.columns:\n",
    "        tmp = df.apply(lambda r: km_ano_e_perfil(r[\"Ano\"], r[\"Quilometragem_Estimada\"]), axis=1)\n",
    "        df[\"KM_Ano_auto\"] = tmp.apply(lambda x: x[0])\n",
    "        df[\"Perfil_Rodagem_auto\"] = tmp.apply(lambda x: x[1])\n",
    "\n",
    "    # Base de compara√ß√£o\n",
    "    X = df[[\"Ano\",\"Quilometragem_Estimada\"]].astype(float).values\n",
    "    xq = np.array([[float(ano), float(km)]])\n",
    "\n",
    "    # Cor (opcional)\n",
    "    if cor is not None:\n",
    "        df[\"match_cor\"] = (df[\"Cor\"] == cor).astype(int)\n",
    "        X = np.hstack([X, df[[\"match_cor\"]].values])\n",
    "        xq = np.hstack([xq, [[1]]])\n",
    "\n",
    "    # Perfil autom√°tico (para o query)\n",
    "    km_ano_q, perfil_q = km_ano_e_perfil(ano, km)\n",
    "    df[\"match_perfil\"] = (df[\"Perfil_Rodagem_auto\"] == perfil_q).astype(int)\n",
    "    X = np.hstack([X, df[[\"match_perfil\"]].values])\n",
    "    xq = np.hstack([xq, [[1]]])\n",
    "\n",
    "    k = min(int(k), len(X))\n",
    "    if k == 0:\n",
    "        return None\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=k)\n",
    "    nn.fit(X)\n",
    "    dist, idx = nn.kneighbors(xq, n_neighbors=k)\n",
    "    viz = df.iloc[idx[0]].copy()\n",
    "    dias = viz[\"Dias_para_Venda\"].astype(float)\n",
    "\n",
    "    q10, q50, q90 = dias.quantile([0.10, 0.50, 0.90])\n",
    "\n",
    "    return {\n",
    "        \"M√©todo\": f\"KNN (k={k}, perfil={perfil_q}, km/ano‚âà{km_ano_q:.0f})\",\n",
    "        \"N\": int(len(viz)),\n",
    "        \"M√≠n\": round(q10,1), \"Med\": round(q50,1), \"M√°x\": round(q90,1),\n",
    "        \"M√©dia ¬± DP\": f\"{dias.mean():.1f} ¬± {dias.std(ddof=1):.1f}\"\n",
    "    }\n",
    "\n",
    "# ====== Modelo de Quantis ======\n",
    "_PRE = None\n",
    "_MODELS = None\n",
    "_FEATURE_COLS = None\n",
    "\n",
    "def build_features_for_training(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    df[\"Idade\"] = (ANO_ATUAL - df[\"Ano\"]).clip(lower=0)\n",
    "    # Garante as colunas autom√°ticas\n",
    "    if \"KM_Ano_auto\" not in df.columns or \"Perfil_Rodagem_auto\" not in df.columns:\n",
    "        tmp = df.apply(lambda r: km_ano_e_perfil(r[\"Ano\"], r[\"Quilometragem_Estimada\"]), axis=1)\n",
    "        df[\"KM_Ano_auto\"] = tmp.apply(lambda x: x[0])\n",
    "        df[\"Perfil_Rodagem_auto\"] = tmp.apply(lambda x: x[1])\n",
    "    for c in [\"Nota_Confianca_Marca\",\"Nota_Confianca_Modelo\",\"Nota_Aparencia\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].fillna(3.0)\n",
    "\n",
    "    feature_cols = [\n",
    "        \"Marca\",\"Modelo\",\"Cor\",\"Perfil_Rodagem_auto\",\n",
    "        \"Nota_Confianca_Marca\",\"Nota_Confianca_Modelo\",\"Nota_Aparencia\",\n",
    "        \"Quilometragem_Estimada\",\"Ano\",\"Idade\",\"KM_Ano_auto\"\n",
    "    ]\n",
    "    return df[feature_cols + [\"Dias_para_Venda\"]], feature_cols\n",
    "\n",
    "def compute_sample_weights(df_like_X_with_y: pd.DataFrame) -> np.ndarray:\n",
    "    key = df_like_X_with_y[\"Marca\"].astype(str) + \"||\" + df_like_X_with_y[\"Modelo\"].astype(str)\n",
    "    counts = key.value_counts()\n",
    "    med = counts.median()\n",
    "    w = key.map(lambda k: float(med) / float(counts[k]))\n",
    "    return w.clip(lower=0.25, upper=4.0).values\n",
    "\n",
    "def train_quantile_model(df_base: pd.DataFrame):\n",
    "    global _PRE, _MODELS, _FEATURE_COLS\n",
    "    df, feature_cols = build_features_for_training(df_base)\n",
    "    X = df[feature_cols]\n",
    "    y = df[\"Dias_para_Venda\"].astype(float).values\n",
    "\n",
    "    cat_cols = [\"Marca\",\"Modelo\",\"Cor\",\"Perfil_Rodagem_auto\"]\n",
    "    num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "    pre = build_preprocessor(cat_cols, num_cols)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "    pre.fit(X_train)\n",
    "    Xt_train = pre.transform(X_train)\n",
    "    Xt_test  = pre.transform(X_test)\n",
    "\n",
    "    w_all = compute_sample_weights(X.assign(Dias_para_Venda=y))\n",
    "    w_train = w_all[X_train.index]\n",
    "\n",
    "    models = fit_quantile_models(Xt_train, y_train, sample_weight=w_train, quantis=QUANTIS)\n",
    "    y_pred_med = models[0.5].predict(Xt_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_med)\n",
    "\n",
    "    _PRE, _MODELS, _FEATURE_COLS = pre, models, feature_cols\n",
    "    return mae\n",
    "\n",
    "def predict_quantis_auto(entrada: dict):\n",
    "    \"\"\"Entrada cont√©m pelo menos: Marca, Modelo, Ano, Quilometragem_Estimada, Cor, Nota_Confianca_Marca, Nota_Confianca_Modelo, Nota_Aparencia.\"\"\"\n",
    "    if _PRE is None or _MODELS is None or _FEATURE_COLS is None:\n",
    "        raise RuntimeError(\"Modelo ainda n√£o treinado. Clique em 'Treinar/Atualizar Modelo' na interface.\")\n",
    "\n",
    "    km_ano, perfil = km_ano_e_perfil(entrada[\"Ano\"], entrada[\"Quilometragem_Estimada\"])\n",
    "    row = {\n",
    "        \"Marca\": entrada[\"Marca\"],\n",
    "        \"Modelo\": entrada[\"Modelo\"],\n",
    "        \"Cor\": entrada[\"Cor\"],\n",
    "        \"Perfil_Rodagem_auto\": perfil,\n",
    "        \"Nota_Confianca_Marca\": float(entrada[\"Nota_Confianca_Marca\"]),\n",
    "        \"Nota_Confianca_Modelo\": float(entrada[\"Nota_Confianca_Modelo\"]),\n",
    "        \"Nota_Aparencia\": float(entrada[\"Nota_Aparencia\"]),\n",
    "        \"Quilometragem_Estimada\": int(entrada[\"Quilometragem_Estimada\"]),\n",
    "        \"Ano\": int(entrada[\"Ano\"]),\n",
    "        \"Idade\": max(0, ANO_ATUAL - int(entrada[\"Ano\"])),\n",
    "        \"KM_Ano_auto\": km_ano\n",
    "    }\n",
    "\n",
    "    X = pd.DataFrame([row])[_FEATURE_COLS]\n",
    "    Xt = _PRE.transform(X)\n",
    "    preds = {q: float(_MODELS[q].predict(Xt)[0]) for q in _MODELS}\n",
    "\n",
    "    return {\n",
    "        \"M√©todo\": f\"Modelo (Quantis, perfil={perfil}, km/ano‚âà{km_ano:.0f})\",\n",
    "        \"N\": None,\n",
    "        \"M√≠n\": round(preds.get(0.1, np.nan),1),\n",
    "        \"Med\": round(preds.get(0.5, np.nan),1),\n",
    "        \"M√°x\": round(preds.get(0.9, np.nan),1),\n",
    "        \"M√©dia ¬± DP\": \"‚Äî\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45c6f761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce0847e9f4b4cf9ab070d55358f3489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Dropdown(description='Marca:', layout=Layout(width='280px'), options=('Chevrolet‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ef0c4d265f4ac1beb6c6f430baabad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Widgets\n",
    "w_marca   = W.Dropdown(options=LIST_MARCAS, description=\"Marca:\", layout=W.Layout(width=\"280px\"))\n",
    "w_modelo  = W.Dropdown(options=[], description=\"Modelo:\", layout=W.Layout(width=\"320px\"))\n",
    "w_ano     = W.IntText(value=2021, description=\"Ano:\", layout=W.Layout(width=\"200px\"))\n",
    "w_km      = W.IntText(value=45000, description=\"KM:\", layout=W.Layout(width=\"220px\"))\n",
    "w_cor     = W.Dropdown(options=LIST_CORES or [\"Branco\"], value=(LIST_CORES[0] if LIST_CORES else \"Branco\"),\n",
    "                       description=\"Cor:\", layout=W.Layout(width=\"240px\"))\n",
    "\n",
    "w_estado  = W.Dropdown(options=LIST_ESTADOS, value=\"bom\", description=\"Estado:\", layout=W.Layout(width=\"260px\"))\n",
    "w_nota    = W.Text(value=\"\", description=\"Nota Apar.:\", placeholder=\"opcional (3.0‚Äì5.0)\", layout=W.Layout(width=\"260px\"))\n",
    "w_k       = W.IntSlider(value=50, min=10, max=200, step=5, description=\"K (KNN):\", readout=True, layout=W.Layout(width=\"420px\"))\n",
    "\n",
    "w_btn_train = W.Button(description=\"Treinar/Atualizar Modelo\", button_style=\"warning\", icon=\"cogs\")\n",
    "w_btn_calc  = W.Button(description=\"Calcular (3 m√©todos)\", button_style=\"success\", icon=\"calculator\")\n",
    "w_out       = W.Output()\n",
    "\n",
    "def on_marca_change(change):\n",
    "    marca = change[\"new\"]\n",
    "    if not marca:\n",
    "        w_modelo.options = []\n",
    "        return\n",
    "    modelos = sorted(DF_BASE.loc[DF_BASE[\"Marca\"]==marca, \"Modelo\"].dropna().unique().tolist())\n",
    "    w_modelo.options = modelos\n",
    "w_marca.observe(on_marca_change, names=\"value\")\n",
    "on_marca_change({\"new\": w_marca.value})\n",
    "\n",
    "def parse_inputs():\n",
    "    marca  = w_marca.value\n",
    "    modelo = w_modelo.value\n",
    "    if not marca or not modelo:\n",
    "        raise ValueError(\"Selecione Marca e Modelo.\")\n",
    "    ano = int(w_ano.value)\n",
    "    km  = int(w_km.value)\n",
    "    cor = w_cor.value\n",
    "\n",
    "    nota_txt = w_nota.value.strip()\n",
    "    if nota_txt:\n",
    "        try:\n",
    "            nota_ap = float(nota_txt)\n",
    "        except:\n",
    "            raise ValueError(\"Nota de apar√™ncia inv√°lida. Use n√∫mero, ex.: 4.2\")\n",
    "    else:\n",
    "        nota_ap = map_estado_para_nota(w_estado.value)\n",
    "\n",
    "    # notas de marca/modelo a partir do dataset (m√©dia) como fallback\n",
    "    nota_marca  = DF_BASE.loc[DF_BASE[\"Marca\"]==marca, \"Nota_Confianca_Marca\"].dropna().mean()\n",
    "    nota_modelo = DF_BASE.loc[(DF_BASE[\"Marca\"]==marca)&(DF_BASE[\"Modelo\"]==modelo), \"Nota_Confianca_Modelo\"].dropna().mean()\n",
    "    if math.isnan(nota_marca):  nota_marca  = 4.0\n",
    "    if math.isnan(nota_modelo): nota_modelo = nota_marca\n",
    "\n",
    "    return {\n",
    "        \"Marca\": marca, \"Modelo\": modelo, \"Ano\": ano,\n",
    "        \"Quilometragem_Estimada\": km, \"Cor\": cor,\n",
    "        \"Nota_Confianca_Marca\": float(nota_marca),\n",
    "        \"Nota_Confianca_Modelo\": float(nota_modelo),\n",
    "        \"Nota_Aparencia\": float(nota_ap)\n",
    "    }\n",
    "\n",
    "def on_train_clicked(_):\n",
    "    with w_out:\n",
    "        clear_output()\n",
    "        try:\n",
    "            mae = train_quantile_model(DF_BASE)\n",
    "            print(f\"‚úÖ Modelo treinado/atualizado. MAE (mediana, teste): {mae:.2f} dias\")\n",
    "        except Exception as e:\n",
    "            print(\"‚ùå Erro ao treinar:\", e)\n",
    "\n",
    "def on_calc_clicked(_):\n",
    "    with w_out:\n",
    "        clear_output()\n",
    "        try:\n",
    "            entrada = parse_inputs()\n",
    "        except Exception as e:\n",
    "            print(\"‚ùå Entrada inv√°lida:\", e)\n",
    "            return\n",
    "\n",
    "        # Emp√≠rico por filtros\n",
    "        r_emp = estimativa_empirica(DF_BASE, entrada[\"Marca\"], entrada[\"Modelo\"], entrada[\"Ano\"], entrada[\"Quilometragem_Estimada\"])\n",
    "        # KNN auto\n",
    "        r_knn = estimativa_knn_auto(DF_BASE, entrada[\"Marca\"], entrada[\"Modelo\"], entrada[\"Ano\"], entrada[\"Quilometragem_Estimada\"],\n",
    "                                    cor=entrada[\"Cor\"], k=w_k.value)\n",
    "        # Quantis (ML)\n",
    "        try:\n",
    "            r_ml = predict_quantis_auto(entrada)\n",
    "        except Exception as e:\n",
    "            r_ml = None\n",
    "            print(\"‚ö†Ô∏è  Modelo ainda n√£o dispon√≠vel. Clique em 'Treinar/Atualizar Modelo'. Detalhe:\", e)\n",
    "\n",
    "        results = [r for r in [r_emp, r_knn, r_ml] if r is not None]\n",
    "        if not results:\n",
    "            print(\"Sem resultados para os filtros dados.\")\n",
    "            return\n",
    "\n",
    "        df_res = pd.DataFrame(results, columns=[\"M√©todo\",\"N\",\"M√≠n\",\"Med\",\"M√°x\",\"M√©dia ¬± DP\"])\n",
    "        display(df_res)\n",
    "\n",
    "        # Consenso simples (mediana entre m√©todos)\n",
    "        mins = [r[\"M√≠n\"] for r in results]; meds = [r[\"Med\"] for r in results]; maxs = [r[\"M√°x\"] for r in results]\n",
    "        cons_min = round(float(np.median(mins)), 1)\n",
    "        cons_med = round(float(np.median(meds)), 1)\n",
    "        cons_max = round(float(np.median(maxs)), 1)\n",
    "\n",
    "        km_ano_q, perfil_q = km_ano_e_perfil(entrada[\"Ano\"], entrada[\"Quilometragem_Estimada\"])\n",
    "        print(f\"\\nüìå Perfil autom√°tico do carro consultado: **{perfil_q}** (km/ano‚âà{km_ano_q:.0f})\")\n",
    "        print(f\"üßÆ Consenso (mediana dos m√©todos): m√≠nimo‚âà{cons_min} dias, m√©dia‚âà{cons_med} dias, m√°ximo‚âà{cons_max} dias.\")\n",
    "\n",
    "w_btn_train.on_click(on_train_clicked)\n",
    "w_btn_calc.on_click(on_calc_clicked)\n",
    "\n",
    "# Layout\n",
    "left  = W.VBox([w_marca, w_modelo, w_ano, w_km, w_cor])\n",
    "right = W.VBox([w_estado, w_nota, w_k, W.HBox([w_btn_train, w_btn_calc])])\n",
    "ui    = W.HBox([left, W.Box(layout=W.Layout(width=\"40px\")), right])\n",
    "\n",
    "display(ui, w_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda09fb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel deu pane ao executar o c√≥digo na c√©lula atual ou em uma c√©lula anterior. \n",
      "\u001b[1;31mAnalise o c√≥digo nas c√©lulas para identificar uma poss√≠vel causa da pane. \n",
      "\u001b[1;31mClique <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqui</a> para obter mais informa√ß√µes. \n",
      "\u001b[1;31mConsulte Jupyter <a href='command:jupyter.viewOutput'>log</a> para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "estimador_gui.py\n",
    "Interface Tkinter para estimar tempo de venda (dias) por 3 abordagens:\n",
    "1) Emp√≠rico direto do banco (quantis por filtros adaptativos)\n",
    "2) KNN (vizinhos mais pr√≥ximos em Ano e KM, com refor√ßo por cor e perfil autom√°tico)\n",
    "3) Modelo de Quantis (GradientBoostingRegressor: 10/50/90%)\n",
    "\n",
    "Banco padr√£o: sorteio_carros100k.db (tabela: sorteio)\n",
    "Menu \"Arquivo -> Abrir banco...\" permite trocar o .db na hora.\n",
    "\"\"\"\n",
    "\n",
    "import os, json, sqlite3, warnings, math, csv\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox, filedialog\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "# -------------------- CONFIG --------------------\n",
    "DEFAULT_DB = \"sorteio_carros100k.db\"\n",
    "TABLE      = \"sorteio\"\n",
    "MODELS_DIR = \"models_gui\"\n",
    "ANO_ATUAL  = 2025\n",
    "QUANTIS    = [0.1, 0.5, 0.9]     # ‚âà min, med, max\n",
    "K_DEFAULT  = 50                  # vizinhos para KNN\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------- ESTADO GLOBAL --------------------\n",
    "DF_BASE = None\n",
    "LIST_MARCAS = []\n",
    "LIST_CORES  = []\n",
    "LIST_PERFIS = []\n",
    "FEATURE_COLS_CACHE = None\n",
    "MODEL_CACHE = None  # (pre, models, meta)\n",
    "LAST_RESULTS = None\n",
    "CURRENT_DB_PATH = os.path.abspath(DEFAULT_DB)\n",
    "\n",
    "# ----------- UTIL: km/ano e perfil autom√°tico -----------\n",
    "def km_ano_e_perfil(ano: int, km_total: int, ano_atual: int = ANO_ATUAL):\n",
    "    \"\"\"\n",
    "    Perfil autom√°tico:\n",
    "      ‚â§ 7.000  -> Pouco Rodado\n",
    "      ‚â§ 12.000 -> Normal\n",
    "      ‚â§ 20.000 -> Alto\n",
    "      > 20.000 -> Super Alto\n",
    "    \"\"\"\n",
    "    idade = max(0, int(ano_atual) - int(ano))\n",
    "    km_ano = float(km_total) / (idade if idade > 0 else 0.5)\n",
    "    if km_ano <= 7000:\n",
    "        perfil = \"Pouco Rodado\"\n",
    "    elif km_ano <= 12000:\n",
    "        perfil = \"Normal\"\n",
    "    elif km_ano <= 20000:\n",
    "        perfil = \"Alto\"\n",
    "    else:\n",
    "        perfil = \"Super Alto\"\n",
    "    return km_ano, perfil\n",
    "\n",
    "def map_estado_para_nota(estado: str) -> float:\n",
    "    if not estado: return 4.0\n",
    "    e = estado.strip().lower()\n",
    "    mapa = {\n",
    "        \"ruim\": 3.0, \"fraco\": 3.0, \"fraca\": 3.0,\n",
    "        \"medio\": 3.5, \"m√©dio\": 3.5, \"regular\": 3.5,\n",
    "        \"bom\": 4.0, \"boa\": 4.0,\n",
    "        \"otimo\": 4.5, \"√≥timo\": 4.5, \"muito bom\": 4.5,\n",
    "        \"excelente\": 4.9\n",
    "    }\n",
    "    return float(mapa.get(e, 4.0))\n",
    "\n",
    "# -------------- CARREGAR DADOS BASE --------------\n",
    "def load_table(db_path: str, table: str) -> pd.DataFrame:\n",
    "    if not os.path.exists(db_path):\n",
    "        raise FileNotFoundError(f\"N√£o encontrei o banco: {db_path}\")\n",
    "    con = sqlite3.connect(db_path)\n",
    "    try:\n",
    "        df = pd.read_sql_query(f\"SELECT * FROM {table}\", con)\n",
    "    finally:\n",
    "        con.close()\n",
    "    if \"Dias_para_Venda\" not in df.columns:\n",
    "        raise ValueError(f\"A tabela {table} precisa ter 'Dias_para_Venda'.\")\n",
    "    return df\n",
    "\n",
    "def prepare_df_base(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    tmp = df.apply(lambda r: km_ano_e_perfil(r[\"Ano\"], r[\"Quilometragem_Estimada\"]), axis=1)\n",
    "    df[\"KM_Ano_auto\"] = tmp.apply(lambda x: x[0])\n",
    "    df[\"Perfil_Rodagem_auto\"] = tmp.apply(lambda x: x[1])\n",
    "    return df\n",
    "\n",
    "def refresh_lists_from_df():\n",
    "    global LIST_MARCAS, LIST_CORES, LIST_PERFIS\n",
    "    LIST_MARCAS = sorted(DF_BASE[\"Marca\"].dropna().unique().tolist())\n",
    "    LIST_CORES  = sorted(DF_BASE[\"Cor\"].dropna().unique().tolist())\n",
    "    LIST_PERFIS = sorted(DF_BASE[\"Perfil_Rodagem_auto\"].dropna().unique().tolist())\n",
    "\n",
    "# --------- PREPROCESSAMENTO E TREINO (MODELO QUANTIS) ---------\n",
    "def build_preprocessor(categorical_cols, numeric_cols):\n",
    "    # compat√≠vel com v√°rias vers√µes do scikit-learn\n",
    "    try:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    except TypeError:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", ohe, categorical_cols),\n",
    "            (\"num\", \"passthrough\", numeric_cols),\n",
    "        ]\n",
    "    )\n",
    "    return pre\n",
    "\n",
    "def build_features(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    df[\"Idade\"] = (ANO_ATUAL - df[\"Ano\"]).clip(lower=0)\n",
    "    # garante colunas autom√°ticas\n",
    "    if \"KM_Ano_auto\" not in df.columns or \"Perfil_Rodagem_auto\" not in df.columns:\n",
    "        tmp = df.apply(lambda r: km_ano_e_perfil(r[\"Ano\"], r[\"Quilometragem_Estimada\"]), axis=1)\n",
    "        df[\"KM_Ano_auto\"] = tmp.apply(lambda x: x[0])\n",
    "        df[\"Perfil_Rodagem_auto\"] = tmp.apply(lambda x: x[1])\n",
    "\n",
    "    for c in [\"Nota_Confianca_Marca\",\"Nota_Confianca_Modelo\",\"Nota_Aparencia\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].fillna(3.0)\n",
    "\n",
    "    feature_cols = [\n",
    "        \"Marca\",\"Modelo\",\"Cor\",\"Perfil_Rodagem_auto\",\n",
    "        \"Nota_Confianca_Marca\",\"Nota_Confianca_Modelo\",\"Nota_Aparencia\",\n",
    "        \"Quilometragem_Estimada\",\"Ano\",\"Idade\",\"KM_Ano_auto\"\n",
    "    ]\n",
    "    return df[feature_cols + [\"Dias_para_Venda\"]], feature_cols\n",
    "\n",
    "def compute_sample_weights(df_like_X_with_y: pd.DataFrame) -> np.ndarray:\n",
    "    key = df_like_X_with_y[\"Marca\"].astype(str) + \"||\" + df_like_X_with_y[\"Modelo\"].astype(str)\n",
    "    counts = key.value_counts()\n",
    "    med = counts.median()\n",
    "    w = key.map(lambda k: float(med) / float(counts[k]))\n",
    "    return w.clip(lower=0.25, upper=4.0).values\n",
    "\n",
    "def fit_quantile_models(X, y, sample_weight, quantis=QUANTIS, random_state=42):\n",
    "    models = {}\n",
    "    for q in quantis:\n",
    "        model = GradientBoostingRegressor(\n",
    "            loss=\"quantile\", alpha=q,\n",
    "            n_estimators=300, learning_rate=0.05, max_depth=3,\n",
    "            subsample=0.9, random_state=random_state\n",
    "        )\n",
    "        model.fit(X, y, sample_weight=sample_weight)\n",
    "        models[q] = model\n",
    "    return models\n",
    "\n",
    "def train_models(df_raw: pd.DataFrame, models_dir: str = MODELS_DIR):\n",
    "    global FEATURE_COLS_CACHE\n",
    "    df, feature_cols = build_features(df_raw)\n",
    "    X = df[feature_cols]\n",
    "    y = df[\"Dias_para_Venda\"].astype(float).values\n",
    "\n",
    "    cat_cols = [\"Marca\",\"Modelo\",\"Cor\",\"Perfil_Rodagem_auto\"]\n",
    "    num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "    pre = build_preprocessor(cat_cols, num_cols)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "    pre.fit(X_train)\n",
    "    Xt_train = pre.transform(X_train)\n",
    "    Xt_test  = pre.transform(X_test)\n",
    "\n",
    "    w_all = compute_sample_weights(X.assign(Dias_para_Venda=y))\n",
    "    w_train = w_all[X_train.index]\n",
    "\n",
    "    models = fit_quantile_models(Xt_train, y_train, sample_weight=w_train)\n",
    "    y_pred_med = models[0.5].predict(Xt_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_med)\n",
    "\n",
    "    # salvar artefatos\n",
    "    joblib.dump(pre, os.path.join(models_dir, \"preprocessor.pkl\"))\n",
    "    for q, m in models.items():\n",
    "        joblib.dump(m, os.path.join(models_dir, f\"gbr_q{int(q*100)}.pkl\"))\n",
    "    meta = {\"feature_cols\": feature_cols, \"quantis\": QUANTIS}\n",
    "    with open(os.path.join(models_dir, \"meta.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    FEATURE_COLS_CACHE = feature_cols\n",
    "    return mae\n",
    "\n",
    "def load_artifacts(models_dir: str = MODELS_DIR):\n",
    "    pre = joblib.load(os.path.join(models_dir, \"preprocessor.pkl\"))\n",
    "    with open(os.path.join(models_dir, \"meta.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        meta = json.load(f)\n",
    "    models = {q: joblib.load(os.path.join(models_dir, f\"gbr_q{int(q*100)}.pkl\")) for q in meta[\"quantis\"]}\n",
    "    return pre, models, meta\n",
    "\n",
    "def ensure_model_trained():\n",
    "    global MODEL_CACHE, FEATURE_COLS_CACHE\n",
    "    try:\n",
    "        MODEL_CACHE = load_artifacts(MODELS_DIR)\n",
    "        FEATURE_COLS_CACHE = MODEL_CACHE[2][\"feature_cols\"]\n",
    "    except Exception:\n",
    "        mae = train_models(DF_BASE, MODELS_DIR)\n",
    "        MODEL_CACHE = load_artifacts(MODELS_DIR)\n",
    "        FEATURE_COLS_CACHE = MODEL_CACHE[2][\"feature_cols\"]\n",
    "        messagebox.showinfo(\"Modelo\", f\"Treino conclu√≠do.\\nMAE (mediana, teste): {mae:.2f} dias\")\n",
    "\n",
    "# ----------- M√âTODO A: EMP√çRICO DIRETO DO BANCO -----------\n",
    "def estimativa_empirica(df_base: pd.DataFrame, marca, modelo, ano, km,\n",
    "                        janela_anos=2, janela_km_perc=0.20, min_amostra=30):\n",
    "    df = df_base[(df_base[\"Marca\"] == marca) & (df_base[\"Modelo\"] == modelo)].copy()\n",
    "    if df.empty:\n",
    "        return None\n",
    "\n",
    "    ano_min, ano_max = ano - janela_anos, ano + janela_anos\n",
    "    km_min, km_max   = km * (1 - janela_km_perc), km * (1 + janela_km_perc)\n",
    "    sub = df[(df[\"Ano\"].between(ano_min, ano_max)) &\n",
    "             (df[\"Quilometragem_Estimada\"].between(km_min, km_max))].copy()\n",
    "\n",
    "    widen = 0\n",
    "    while len(sub) < min_amostra and widen < 3:\n",
    "        widen += 1\n",
    "        ano_min, ano_max = ano - (janela_anos + widen), ano + (janela_anos + widen)\n",
    "        p2 = janela_km_perc + 0.10*widen\n",
    "        km_min, km_max = km * (1 - p2), km * (1 + p2)\n",
    "        sub = df[(df[\"Ano\"].between(ano_min, ano_max)) &\n",
    "                 (df[\"Quilometragem_Estimada\"].between(km_min, km_max))].copy()\n",
    "\n",
    "    if sub.empty:\n",
    "        return None\n",
    "\n",
    "    dias = sub[\"Dias_para_Venda\"].astype(float)\n",
    "    q10, q50, q90 = dias.quantile([0.10, 0.50, 0.90])\n",
    "    media, desvio = dias.mean(), dias.std(ddof=1)\n",
    "\n",
    "    return {\n",
    "        \"label\": \"Emp√≠rico (filtros)\",\n",
    "        \"n\": int(len(sub)),\n",
    "        \"min\": round(q10,1), \"med\": round(q50,1), \"max\": round(q90,1),\n",
    "        \"mean_std\": f\"{media:.1f} ¬± {desvio:.1f}\"\n",
    "    }\n",
    "\n",
    "# ----------- M√âTODO B: KNN -----------\n",
    "def estimativa_knn_auto(df_base: pd.DataFrame, marca, modelo, ano, km, cor=None, k=K_DEFAULT):\n",
    "    df = df_base[(df_base[\"Marca\"] == marca) & (df_base[\"Modelo\"] == modelo)].copy()\n",
    "    if df.empty:\n",
    "        return None\n",
    "\n",
    "    # garante colunas autom√°ticas\n",
    "    if \"KM_Ano_auto\" not in df.columns or \"Perfil_Rodagem_auto\" not in df.columns:\n",
    "        tmp = df.apply(lambda r: km_ano_e_perfil(r[\"Ano\"], r[\"Quilometragem_Estimada\"]), axis=1)\n",
    "        df[\"KM_Ano_auto\"] = tmp.apply(lambda x: x[0])\n",
    "        df[\"Perfil_Rodagem_auto\"] = tmp.apply(lambda x: x[1])\n",
    "\n",
    "    X = df[[\"Ano\",\"Quilometragem_Estimada\"]].astype(float).values\n",
    "    xq = np.array([[float(ano), float(km)]])\n",
    "\n",
    "    # Cor (opcional)\n",
    "    if cor is not None:\n",
    "        df[\"match_cor\"] = (df[\"Cor\"]==cor).astype(int)\n",
    "        X = np.hstack([X, df[[\"match_cor\"]].values])\n",
    "        xq = np.hstack([xq, [[1]]])\n",
    "\n",
    "    # Perfil autom√°tico do query\n",
    "    km_ano_q, perfil_q = km_ano_e_perfil(ano, km)\n",
    "    df[\"match_perfil\"] = (df[\"Perfil_Rodagem_auto\"]==perfil_q).astype(int)\n",
    "    X = np.hstack([X, df[[\"match_perfil\"]].values])\n",
    "    xq = np.hstack([xq, [[1]]])\n",
    "\n",
    "    k = min(int(k), len(X))\n",
    "    if k == 0:\n",
    "        return None\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=k)\n",
    "    nn.fit(X)\n",
    "    dist, idx = nn.kneighbors(xq, n_neighbors=k)\n",
    "    viz = df.iloc[idx[0]].copy()\n",
    "    dias = viz[\"Dias_para_Venda\"].astype(float)\n",
    "\n",
    "    q10, q50, q90 = dias.quantile([0.10, 0.50, 0.90])\n",
    "\n",
    "    return {\n",
    "        \"label\": f\"KNN (k={k}, perfil={perfil_q}, km/ano‚âà{km_ano_q:.0f})\",\n",
    "        \"n\": int(len(viz)),\n",
    "        \"min\": round(q10,1), \"med\": round(q50,1), \"max\": round(q90,1),\n",
    "        \"mean_std\": f\"{dias.mean():.1f} ¬± {dias.std(ddof=1):.1f}\"\n",
    "    }\n",
    "\n",
    "# ----------- M√âTODO C: MODELO DE QUANTIS -----------\n",
    "def predict_quantis(row_dict, pre, models, feature_cols):\n",
    "    km_ano, perfil = km_ano_e_perfil(row_dict[\"Ano\"], row_dict[\"Quilometragem_Estimada\"])\n",
    "    row = {\n",
    "        \"Marca\": row_dict[\"Marca\"],\n",
    "        \"Modelo\": row_dict[\"Modelo\"],\n",
    "        \"Cor\": row_dict[\"Cor\"],\n",
    "        \"Perfil_Rodagem_auto\": perfil,\n",
    "        \"Nota_Confianca_Marca\": float(row_dict[\"Nota_Confianca_Marca\"]),\n",
    "        \"Nota_Confianca_Modelo\": float(row_dict[\"Nota_Confianca_Modelo\"]),\n",
    "        \"Nota_Aparencia\": float(row_dict[\"Nota_Aparencia\"]),\n",
    "        \"Quilometragem_Estimada\": int(row_dict[\"Quilometragem_Estimada\"]),\n",
    "        \"Ano\": int(row_dict[\"Ano\"]),\n",
    "        \"Idade\": max(0, ANO_ATUAL - int(row_dict[\"Ano\"])),\n",
    "        \"KM_Ano_auto\": km_ano\n",
    "    }\n",
    "    X = pd.DataFrame([row])[feature_cols]\n",
    "    Xt = pre.transform(X)\n",
    "    preds = {q: float(models[q].predict(Xt)[0]) for q in models}\n",
    "    return {\n",
    "        \"label\": f\"Modelo (Quantis, perfil={perfil}, km/ano‚âà{km_ano:.0f})\",\n",
    "        \"n\": None,\n",
    "        \"min\": round(preds.get(0.1, np.nan),1),\n",
    "        \"med\": round(preds.get(0.5, np.nan),1),\n",
    "        \"max\": round(preds.get(0.9, np.nan),1),\n",
    "        \"mean_std\": \"‚Äî\"\n",
    "    }\n",
    "\n",
    "# -------------------- GUI (Tkinter) --------------------\n",
    "root = tk.Tk()\n",
    "root.title(\"Estimador de Tempo de Venda (3 m√©todos)\")\n",
    "root.geometry(\"1024x680\")\n",
    "\n",
    "# ---- MENUS ----\n",
    "menubar = tk.Menu(root)\n",
    "root.config(menu=menubar)\n",
    "\n",
    "def menu_abrir_db():\n",
    "    global DF_BASE, CURRENT_DB_PATH, LIST_MARCAS, LIST_CORES\n",
    "    path = filedialog.askopenfilename(\n",
    "        title=\"Abrir banco SQLite\",\n",
    "        filetypes=[(\"SQLite DB\", \"*.db\"), (\"Todos\", \"*.*\")]\n",
    "    )\n",
    "    if not path:\n",
    "        return\n",
    "    try:\n",
    "        df = load_table(path, TABLE)\n",
    "        df = prepare_df_base(df)\n",
    "        DF_BASE = df\n",
    "        CURRENT_DB_PATH = os.path.abspath(path)\n",
    "        refresh_lists_from_df()\n",
    "        # atualiza combos\n",
    "        cb_marca[\"values\"] = LIST_MARCAS\n",
    "        cb_cor[\"values\"]   = LIST_CORES if LIST_CORES else [\"Branco\"]\n",
    "        if LIST_MARCAS:\n",
    "            cb_marca.set(LIST_MARCAS[0])\n",
    "            on_select_marca()\n",
    "        if LIST_CORES:\n",
    "            cb_cor.set(LIST_CORES[0])\n",
    "        lbl_db.config(text=f\"Banco: {CURRENT_DB_PATH} | Tabela: {TABLE}\")\n",
    "        messagebox.showinfo(\"Banco\", f\"Banco carregado:\\n{CURRENT_DB_PATH}\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Erro ao abrir banco\", str(e))\n",
    "\n",
    "def menu_sobre():\n",
    "    messagebox.showinfo(\n",
    "        \"Sobre\",\n",
    "        \"Estimador de Tempo de Venda\\nM√©todos: Emp√≠rico, KNN e Quantis (GBR)\\nFeito para Paulo üòâ\"\n",
    "    )\n",
    "\n",
    "men_arquivo = tk.Menu(menubar, tearoff=0)\n",
    "men_arquivo.add_command(label=\"Abrir banco...\", command=menu_abrir_db)\n",
    "men_arquivo.add_separator()\n",
    "men_arquivo.add_command(label=\"Sair\", command=root.destroy)\n",
    "menubar.add_cascade(label=\"Arquivo\", menu=men_arquivo)\n",
    "\n",
    "men_ajuda = tk.Menu(menubar, tearoff=0)\n",
    "men_ajuda.add_command(label=\"Sobre\", command=menu_sobre)\n",
    "menubar.add_cascade(label=\"Ajuda\", menu=men_ajuda)\n",
    "\n",
    "# ---- FRAMES ----\n",
    "main = ttk.Frame(root, padding=12)\n",
    "main.pack(fill=\"both\", expand=True)\n",
    "\n",
    "# Linha 1: sele√ß√£o de marca/modelo\n",
    "row1 = ttk.Frame(main); row1.pack(fill=\"x\", pady=4)\n",
    "ttk.Label(row1, text=\"Marca:\").pack(side=\"left\")\n",
    "cb_marca = ttk.Combobox(row1, values=[], width=22, state=\"readonly\")\n",
    "cb_marca.pack(side=\"left\", padx=6)\n",
    "\n",
    "ttk.Label(row1, text=\"Modelo:\").pack(side=\"left\")\n",
    "cb_modelo = ttk.Combobox(row1, values=[], width=30, state=\"readonly\")\n",
    "cb_modelo.pack(side=\"left\", padx=6)\n",
    "\n",
    "def on_select_marca(event=None):\n",
    "    marca = cb_marca.get()\n",
    "    if not marca or DF_BASE is None:\n",
    "        cb_modelo[\"values\"] = []\n",
    "        return\n",
    "    lista = sorted(DF_BASE.loc[DF_BASE[\"Marca\"]==marca, \"Modelo\"].dropna().unique().tolist())\n",
    "    cb_modelo[\"values\"] = lista\n",
    "cb_marca.bind(\"<<ComboboxSelected>>\", on_select_marca)\n",
    "\n",
    "# Linha 2: ano/km/cor\n",
    "row2 = ttk.Frame(main); row2.pack(fill=\"x\", pady=4)\n",
    "ttk.Label(row2, text=\"Ano:\").pack(side=\"left\")\n",
    "ent_ano = ttk.Entry(row2, width=8); ent_ano.insert(0, \"2021\"); ent_ano.pack(side=\"left\", padx=6)\n",
    "\n",
    "ttk.Label(row2, text=\"KM:\").pack(side=\"left\")\n",
    "ent_km = ttk.Entry(row2, width=12); ent_km.insert(0, \"45000\"); ent_km.pack(side=\"left\", padx=6)\n",
    "\n",
    "ttk.Label(row2, text=\"Cor:\").pack(side=\"left\")\n",
    "cb_cor = ttk.Combobox(row2, values=[], width=16, state=\"readonly\")\n",
    "cb_cor.pack(side=\"left\", padx=6)\n",
    "\n",
    "# Linha 3: estado/nota e K\n",
    "row3 = ttk.Frame(main); row3.pack(fill=\"x\", pady=4)\n",
    "ttk.Label(row3, text=\"Estado (ruim/medio/bom/otimo/excelente):\").pack(side=\"left\")\n",
    "cb_estado = ttk.Combobox(row3, values=[\"ruim\",\"medio\",\"bom\",\"otimo\",\"excelente\"], width=18, state=\"readonly\")\n",
    "cb_estado.set(\"bom\"); cb_estado.pack(side=\"left\", padx=6)\n",
    "\n",
    "ttk.Label(row3, text=\"ou Nota Apar√™ncia (3.0‚Äì5.0):\").pack(side=\"left\")\n",
    "ent_nota = ttk.Entry(row3, width=6); ent_nota.insert(0, \"\"); ent_nota.pack(side=\"left\", padx=6)\n",
    "\n",
    "ttk.Label(row3, text=\"K (KNN):\").pack(side=\"left\")\n",
    "ent_k = ttk.Entry(row3, width=6); ent_k.insert(0, str(K_DEFAULT)); ent_k.pack(side=\"left\", padx=6)\n",
    "\n",
    "# Bot√µes\n",
    "row_btn = ttk.Frame(main); row_btn.pack(fill=\"x\", pady=8)\n",
    "btn_treinar = ttk.Button(row_btn, text=\"Treinar/Carregar Modelo\", width=24)\n",
    "btn_calcular = ttk.Button(row_btn, text=\"Calcular (3 m√©todos)\", width=24)\n",
    "btn_export   = ttk.Button(row_btn, text=\"Exportar tabela (CSV)\", width=24)\n",
    "btn_treinar.pack(side=\"left\", padx=6)\n",
    "btn_calcular.pack(side=\"left\", padx=6)\n",
    "btn_export.pack(side=\"left\", padx=6)\n",
    "\n",
    "# Tabela de resultados\n",
    "cols = (\"metodo\",\"n\",\"min\",\"med\",\"max\",\"mean_std\")\n",
    "tree = ttk.Treeview(main, columns=cols, show=\"headings\", height=12)\n",
    "for c, txt, w in [\n",
    "    (\"metodo\",\"M√©todo\",320),\n",
    "    (\"n\",\"N\",60),\n",
    "    (\"min\",\"M√≠n\",80),\n",
    "    (\"med\",\"Med\",80),\n",
    "    (\"max\",\"M√°x\",80),\n",
    "    (\"mean_std\",\"M√©dia ¬± DP\",180),\n",
    "]:\n",
    "    tree.heading(c, text=txt)\n",
    "    tree.column(c, width=w, anchor=\"center\")\n",
    "tree.pack(fill=\"both\", expand=True, pady=6)\n",
    "\n",
    "# Resumo/consenso\n",
    "lbl_consenso = ttk.Label(main, text=\"Consenso: ‚Äî\", font=(\"TkDefaultFont\", 11, \"bold\"))\n",
    "lbl_consenso.pack(anchor=\"w\", pady=6)\n",
    "\n",
    "# Rodap√© com caminho do banco\n",
    "lbl_db = ttk.Label(main, text=f\"Banco: {CURRENT_DB_PATH} | Tabela: {TABLE}\", foreground=\"#555\")\n",
    "lbl_db.pack(anchor=\"w\", pady=4)\n",
    "\n",
    "# -------------- FUN√á√ïES DE A√á√ÉO --------------\n",
    "def init_load_default_db():\n",
    "    global DF_BASE, CURRENT_DB_PATH\n",
    "    try:\n",
    "        DF_BASE = load_table(DEFAULT_DB, TABLE)\n",
    "        DF_BASE = prepare_df_base(DF_BASE)\n",
    "        CURRENT_DB_PATH = os.path.abspath(DEFAULT_DB)\n",
    "    except Exception as e:\n",
    "        messagebox.showwarning(\"Banco padr√£o\", f\"N√£o consegui abrir {DEFAULT_DB}.\\nUse Arquivo -> Abrir banco...\\n\\n{e}\")\n",
    "        return\n",
    "    refresh_lists_from_df()\n",
    "    cb_marca[\"values\"] = LIST_MARCAS\n",
    "    cb_cor[\"values\"]   = LIST_CORES if LIST_CORES else [\"Branco\"]\n",
    "    if LIST_MARCAS:\n",
    "        cb_marca.set(LIST_MARCAS[0]); on_select_marca()\n",
    "    if LIST_CORES:\n",
    "        cb_cor.set(LIST_CORES[0])\n",
    "    lbl_db.config(text=f\"Banco: {CURRENT_DB_PATH} | Tabela: {TABLE}\")\n",
    "\n",
    "def action_treinar():\n",
    "    global MODEL_CACHE, FEATURE_COLS_CACHE\n",
    "    if DF_BASE is None:\n",
    "        messagebox.showerror(\"Erro\", \"Carregue um banco primeiro (Arquivo -> Abrir banco...).\")\n",
    "        return\n",
    "    try:\n",
    "        mae = train_models(DF_BASE, MODELS_DIR)\n",
    "        MODEL_CACHE = load_artifacts(MODELS_DIR)\n",
    "        FEATURE_COLS_CACHE = MODEL_CACHE[2][\"feature_cols\"]\n",
    "        messagebox.showinfo(\"Modelo\", f\"Treino conclu√≠do.\\nMAE (mediana, teste): {mae:.2f} dias\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Erro ao treinar\", str(e))\n",
    "\n",
    "def parse_inputs():\n",
    "    if DF_BASE is None:\n",
    "        raise ValueError(\"Carregue um banco primeiro (Arquivo -> Abrir banco...).\")\n",
    "    marca = cb_marca.get().strip()\n",
    "    modelo = cb_modelo.get().strip()\n",
    "    if not marca or not modelo:\n",
    "        raise ValueError(\"Selecione Marca e Modelo.\")\n",
    "    try:\n",
    "        ano = int(ent_ano.get().strip())\n",
    "        km  = int(ent_km.get().strip())\n",
    "    except:\n",
    "        raise ValueError(\"Ano e KM precisam ser n√∫meros inteiros.\")\n",
    "    cor = cb_cor.get().strip() or None\n",
    "\n",
    "    nota_txt = ent_nota.get().strip()\n",
    "    if nota_txt:\n",
    "        try:\n",
    "            nota = float(nota_txt)\n",
    "        except:\n",
    "            raise ValueError(\"Nota de apar√™ncia inv√°lida (use n√∫mero, ex.: 4.2).\")\n",
    "    else:\n",
    "        nota = map_estado_para_nota(cb_estado.get())\n",
    "\n",
    "    # notas de marca/modelo a partir do dataset (m√©dia) como fallback\n",
    "    nota_marca  = DF_BASE.loc[DF_BASE[\"Marca\"]==marca, \"Nota_Confianca_Marca\"].dropna().mean()\n",
    "    nota_modelo = DF_BASE.loc[(DF_BASE[\"Marca\"]==marca)&(DF_BASE[\"Modelo\"]==modelo), \"Nota_Confianca_Modelo\"].dropna().mean()\n",
    "    if math.isnan(nota_marca):  nota_marca  = 4.0\n",
    "    if math.isnan(nota_modelo): nota_modelo = nota_marca\n",
    "\n",
    "    return {\n",
    "        \"Marca\": marca, \"Modelo\": modelo, \"Ano\": ano,\n",
    "        \"Quilometragem_Estimada\": km, \"Cor\": cor,\n",
    "        \"Nota_Confianca_Marca\": float(nota_marca),\n",
    "        \"Nota_Confianca_Modelo\": float(nota_modelo),\n",
    "        \"Nota_Aparencia\": float(nota)\n",
    "    }\n",
    "\n",
    "def action_calcular():\n",
    "    global LAST_RESULTS\n",
    "    for i in tree.get_children():\n",
    "        tree.delete(i)\n",
    "    try:\n",
    "        entrada = parse_inputs()\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Entrada inv√°lida\", str(e))\n",
    "        return\n",
    "\n",
    "    # A) Emp√≠rico por filtros\n",
    "    r_emp = estimativa_empirica(DF_BASE, entrada[\"Marca\"], entrada[\"Modelo\"], entrada[\"Ano\"], entrada[\"Quilometragem_Estimada\"])\n",
    "    # B) KNN\n",
    "    try:\n",
    "        k = int(ent_k.get().strip())\n",
    "    except:\n",
    "        k = K_DEFAULT\n",
    "    r_knn = estimativa_knn_auto(\n",
    "        DF_BASE, entrada[\"Marca\"], entrada[\"Modelo\"], entrada[\"Ano\"], entrada[\"Quilometragem_Estimada\"],\n",
    "        cor=entrada[\"Cor\"], k=k\n",
    "    )\n",
    "    # C) Modelo Quantis\n",
    "    try:\n",
    "        if MODEL_CACHE is None or FEATURE_COLS_CACHE is None:\n",
    "            ensure_model_trained()\n",
    "        pre, models, meta = MODEL_CACHE\n",
    "        r_ml = predict_quantis(entrada, pre, models, FEATURE_COLS_CACHE)\n",
    "    except Exception as e:\n",
    "        r_ml = None\n",
    "        messagebox.showwarning(\"Modelo\", f\"N√£o foi poss√≠vel usar o modelo: {e}\")\n",
    "\n",
    "    resultados = [r for r in [r_emp, r_knn, r_ml] if r is not None]\n",
    "    if not resultados:\n",
    "        messagebox.showinfo(\"Sem resultados\", \"Nenhum m√©todo retornou estimativa para esses filtros.\")\n",
    "        lbl_consenso.config(text=\"Consenso: ‚Äî\")\n",
    "        LAST_RESULTS = None\n",
    "        return\n",
    "\n",
    "    for r in resultados:\n",
    "        tree.insert(\"\", \"end\", values=(r[\"label\"], r[\"n\"], r[\"min\"], r[\"med\"], r[\"max\"], r[\"mean_std\"]))\n",
    "\n",
    "    # consenso simples\n",
    "    mins = [r[\"min\"] for r in resultados]\n",
    "    meds = [r[\"med\"] for r in resultados]\n",
    "    maxs = [r[\"max\"] for r in resultados]\n",
    "    cons_min = round(float(np.median(mins)), 1)\n",
    "    cons_med = round(float(np.median(meds)), 1)\n",
    "    cons_max = round(float(np.median(maxs)), 1)\n",
    "\n",
    "    km_ano_q, perfil_q = km_ano_e_perfil(entrada[\"Ano\"], entrada[\"Quilometragem_Estimada\"])\n",
    "    lbl_consenso.config(\n",
    "        text=f\"Perfil auto: {perfil_q} (km/ano‚âà{km_ano_q:.0f}) | Consenso: m√≠nimo‚âà{cons_min} ‚Ä¢ m√©dia‚âà{cons_med} ‚Ä¢ m√°ximo‚âà{cons_max} dias\"\n",
    "    )\n",
    "\n",
    "    LAST_RESULTS = {\n",
    "        \"entrada\": entrada,\n",
    "        \"resultados\": resultados,\n",
    "        \"consenso\": {\"min\": cons_min, \"med\": cons_med, \"max\": cons_max},\n",
    "        \"db\": CURRENT_DB_PATH\n",
    "    }\n",
    "\n",
    "def action_export():\n",
    "    if not LAST_RESULTS:\n",
    "        messagebox.showinfo(\"Exportar\", \"Calcule primeiro para exportar a tabela.\")\n",
    "        return\n",
    "    path = filedialog.asksaveasfilename(\n",
    "        title=\"Salvar resultados como CSV\",\n",
    "        defaultextension=\".csv\",\n",
    "        filetypes=[(\"CSV\", \"*.csv\")]\n",
    "    )\n",
    "    if not path:\n",
    "        return\n",
    "    try:\n",
    "        with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            w = csv.writer(f, delimiter=\";\")\n",
    "            w.writerow([\"Banco\", LAST_RESULTS[\"db\"]])\n",
    "            ent = LAST_RESULTS[\"entrada\"]\n",
    "            w.writerow([\"Entrada\"])\n",
    "            for k, v in ent.items():\n",
    "                w.writerow([k, v])\n",
    "            w.writerow([])\n",
    "            w.writerow([\"M√©todo\",\"N\",\"M√≠n\",\"Med\",\"M√°x\",\"M√©dia ¬± DP\"])\n",
    "            for r in LAST_RESULTS[\"resultados\"]:\n",
    "                w.writerow([r[\"label\"], r[\"n\"], r[\"min\"], r[\"med\"], r[\"max\"], r[\"mean_std\"]])\n",
    "            w.writerow([])\n",
    "            cons = LAST_RESULTS[\"consenso\"]\n",
    "            w.writerow([\"Consenso\", \"\", cons[\"min\"], cons[\"med\"], cons[\"max\"], \"\"])\n",
    "        messagebox.showinfo(\"Exportar\", f\"Arquivo salvo:\\n{path}\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Exportar\", str(e))\n",
    "\n",
    "btn_treinar.config(command=action_treinar)\n",
    "btn_calcular.config(command=action_calcular)\n",
    "btn_export.config(command=action_export)\n",
    "\n",
    "# Carrega DB padr√£o na inicializa√ß√£o\n",
    "init_load_default_db()\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba39f25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
